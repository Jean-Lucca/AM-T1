# -*- coding: utf-8 -*-
"""AM - T1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4rXe5jbZnh8bpfe14nlER5k3FYhkQWL
"""

# ============================================
# Dependencias
# ============================================
!pip install shap lime seaborn matplotlib scikit-learn pandas ucimlrepo --quiet

import os
import urllib.request
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)

import shap
from lime.lime_tabular import LimeTabularExplainer

# ============================================
# Dataset escolhido
# ============================================
local_csv = "bank-additional-full.csv"

df = pd.read_csv(local_csv, sep=";")
df["y_bin"] = df["y"].map({"no": 0, "yes": 1})
print("Shape:", df.shape)
print(df["y"].value_counts())

# ============================================
# Pré-processamento
# ============================================
cat_cols = df.select_dtypes(include=["object"]).columns.tolist()
cat_cols.remove("y")
num_cols = df.select_dtypes(include=["int64","float64"]).columns.tolist()
if "y_bin" in num_cols: num_cols.remove("y_bin")
# Para variáveis numéricas: substitui valores faltantes pela mediana + padroniza.
numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])
# Para variáveis categóricas: substitui missing + aplica one-hot encoding.
categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="constant", fill_value="missing")),
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])
# Combina transformações em um único objeto para aplicar a cada tipo de coluna.
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, num_cols),
        ("cat", categorical_transformer, cat_cols)
    ]
)
# Separa features (X) e alvo (y).
# Divide em treino e teste (80/20), mantendo proporção da classe.
X = df.drop(columns=["y","y_bin"])
y = df["y_bin"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ============================================
# Modelos e GridSearch
# ============================================
# Validação cruzada estratificada (5 folds).
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# Cria pipelines para cada modelo, aplicando o pré-processamento antes do classificador.
pipe_knn = Pipeline([("pre", preprocessor), ("clf", KNeighborsClassifier())])
pipe_nb  = Pipeline([("pre", preprocessor), ("clf", GaussianNB())])
pipe_dt  = Pipeline([("pre", preprocessor), ("clf", DecisionTreeClassifier(random_state=42))])
# Define grades de hiperparâmetros para buscar com GridSearch.
param_knn = {"clf__n_neighbors": [3,5,7], "clf__weights": ["uniform","distance"]}
param_nb  = {"clf__var_smoothing": [1e-9, 1e-8, 1e-7]}
param_dt  = {"clf__max_depth": [5,10,20,None], "clf__criterion": ["gini","entropy"]}
# Configura GridSearchCV para os três modelos (métrica = F1).
grid_knn = GridSearchCV(pipe_knn, param_knn, cv=cv, scoring="f1", n_jobs=-1)
grid_nb  = GridSearchCV(pipe_nb, param_nb, cv=cv, scoring="f1", n_jobs=-1)
grid_dt  = GridSearchCV(pipe_dt, param_dt, cv=cv, scoring="f1", n_jobs=-1)
# Treina os modelos e busca melhores hiperparâmetros.
print("Treinando KNN..."); grid_knn.fit(X_train, y_train)
print("Treinando NB...");  grid_nb.fit(X_train, y_train)
print("Treinando DT...");  grid_dt.fit(X_train, y_train)

# ============================================
# Avaliação
# ============================================
# Guarda os melhores modelos encontrados.
models = {
    "KNN": grid_knn.best_estimator_,
    "GaussianNB": grid_nb.best_estimator_,
    "DecisionTree": grid_dt.best_estimator_
}
# Para cada modelo:
# Faz previsões (y_pred);
# Calcula probabilidades (se possível);
# Mede métricas (accuracy, precision, recall, f1, ROC AUC);
# Mostra relatório detalhado.
results = {}
for name, model in models.items():
    y_pred = model.predict(X_test)
    try:
        y_proba = model.predict_proba(X_test)[:,1]
    except:
        y_proba = None
    results[name] = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "roc_auc": roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan
    }
    print(f"\n{name}:\n", classification_report(y_test, y_pred))
# Cria DataFrame comparativo com métricas.
results_df = pd.DataFrame(results).T
print("\nResumo métricas:\n", results_df)

# ============================================
# Interpretabilidade - Decision Tree
# ============================================
# Ajusta pré-processador para recuperar nomes das features após one-hot encoding.
preprocessor.fit(X_train)
ohe = preprocessor.named_transformers_["cat"].named_steps["onehot"]
feature_names = num_cols + list(ohe.get_feature_names_out(cat_cols))
# Pega a árvore de decisão treinada.
best_dt = grid_dt.best_estimator_.named_steps["clf"]
# Extrai importâncias das features e mostra as 15 principais.
importances = best_dt.feature_importances_
imp_df = pd.DataFrame({"feature": feature_names, "importance": importances})
imp_df = imp_df.sort_values("importance", ascending=False).head(15)
# Plota gráfico de barras com importâncias.
plt.figure(figsize=(8,6))
sns.barplot(data=imp_df, x="importance", y="feature")
plt.title("Top 15 Importâncias (Decision Tree)")
plt.show()

# ============================================
# Interpretabilidade - KNN com LIME
# ============================================
# Transforma dados (numéricos + one-hot).
X_train_pre = preprocessor.transform(X_train)
X_test_pre  = preprocessor.transform(X_test)
# Cria explicador LIME para classificação tabular.
explainer = LimeTabularExplainer(
    training_data=np.array(X_train_pre),
    feature_names=feature_names,
    class_names=["no","yes"],
    mode="classification"
)
# Escolhe uma instância aleatória do conjunto de teste.
idx = np.random.randint(0, X_test.shape[0])
# Define função auxiliar para fornecer probabilidades do KNN já treinado.
# Define a custom prediction function that uses the trained classifier on preprocessed data
def predict_proba_knn_classifier(data_preprocessed):
    # Access the trained classifier directly from the pipeline
    return grid_knn.best_estimator_.named_steps['clf'].predict_proba(data_preprocessed)

# Explica a instância selecionada e mostra a contribuição das features.
exp = explainer.explain_instance(
    data_row=X_test_pre[idx],
    predict_fn=predict_proba_knn_classifier # Use the custom prediction function
)
print("\nLIME explicação KNN:\n", exp.as_list())
exp.show_in_notebook(show_table=True)

# ============================================
# Interpretabilidade - SHAP para Decision Tree
# ============================================
# Inicializa SHAP;
# Cria explicador otimizado para árvore de decisão;
# Calcula valores SHAP no conjunto de teste;
# Mostra gráfico de resumo com as features mais influentes.
shap.initjs()
explainer_shap = shap.TreeExplainer(best_dt)
shap_values = explainer_shap.shap_values(X_test_pre)

shap.summary_plot(shap_values, features=X_test_pre, feature_names=feature_names)

# ============================================
# Interpretabilidade - Naïve Bayes
# ============================================
# Pega o modelo NB treinado (pós-preprocessing).
best_nb = grid_nb.best_estimator_.named_steps["clf"]

# Para GaussianNB, acessa probabilidades log condicionais: feature_log_prob_[class_idx, feature_idx]
# Mas como há one-hot, focamos em features originais numéricas (cat one-hot dilui; assumimos análise em num para simplicidade).
# Exemplo: probs para classes 0 ("no") e 1 ("yes") em features numéricas chave (ex.: duration, euribor3m).
# Nota: GaussianNB assume normal; mean_ e var_ definem distribuições condicionais.

print("\n=== Análise de Probabilidades Condicionais no Naïve Bayes ===")
# Features numéricas originais (sem one-hot).
num_feature_names = num_cols  # ['age', 'duration', 'campaign', etc.]

# Probabilidades médias condicionais (aprox. via mean_ para Gaussiana).
means_class0 = best_nb.theta_[0]  # Média por feature | class=0 ("no")
means_class1 = best_nb.theta_[1]  # Média por feature | class=1 ("yes")

# Exemplo para top features numéricas (baseado em DT importâncias).
key_num_features = ['duration', 'euribor3m', 'nr.employed', 'age']  # Ajuste índices se necessário.
for feat in key_num_features:
    if feat in num_feature_names:
        idx = num_feature_names.index(feat)
        print(f"{feat}:")
        print(f"  Média | 'no': {means_class0[idx]:.2f} (baixa duração/euro alto → 'no')")
        print(f"  Média | 'yes': {means_class1[idx]:.2f} (alta duração/euro baixo → 'yes')")
        # Discussão: Alta duration aumenta P(yes) via P(duration|yes) > P(duration|no), assumindo independência.

# Plot comparativo de means para visualização.
plt.figure(figsize=(10, 6))
x_pos = np.arange(len(key_num_features))
plt.bar(x_pos - 0.2, means_class0[[num_feature_names.index(f) for f in key_num_features]], 0.4, label="'no'", alpha=0.8)
plt.bar(x_pos + 0.2, means_class1[[num_feature_names.index(f) for f in key_num_features]], 0.4, label="'yes'", alpha=0.8)
plt.xlabel("Features Numéricas")
plt.ylabel("Média Condicional")
plt.title("Probabilidades Condicionais Aproximadas (Médias) no NB")
plt.xticks(x_pos, key_num_features)
plt.legend()
plt.show()

# Discussão textual (adicione ao README ou print):
print("\nDiscussão: No NB, probabilidades condicionais assumem independência. Ex.: P(duration|yes) alta (média ~500s) vs. P(duration|no) baixa (~200s), influenciando previsões – chamadas longas sugerem interesse ('yes'). Limitação: Ignora correlações (ex.: duration e month). Para cat, one-hot torna análise verbosa; probs via classes_ em one-hot steps.")

# ============================================
# 4. Comparação e Análise
# ============================================
print("\n=== Comparação e Análise de Interpretabilidade ===")

# Extraia importâncias/relevâncias de todos modelos para comparação.
# DT: Já temos imp_df (top 15).
# NB: Aprox. via mutual_info_classif (permutation-like) ou abs(mean diff).
from sklearn.feature_selection import mutual_info_classif

# Calcula mutual info para todos (global importance, agnóstico).
mi_scores = mutual_info_classif(X_train_pre, y_train, random_state=42)
mi_df = pd.DataFrame({"feature": feature_names, "mutual_info": mi_scores})
mi_df = mi_df.sort_values("mutual_info", ascending=False).head(15)

print("Top 15 Mutual Info (comum a todos modelos):")
print(mi_df)

# Compara top features entre DT e MI (proxy para NB/KNN).
common_top = set(imp_df['feature'].head(5)) & set(mi_df['feature'].head(5))
print(f"\nModelos concordam em variáveis relevantes? Sim, em {len(common_top)}/5 top: {common_top} (ex.: 'duration' globalmente importante).")

# Respostas às perguntas:
print("\n1. Os resultados fizeram sentido? Sim: Features como 'duration' (tempo de chamada) e 'euribor3m' (taxa econômica) influenciam 'yes' (interesse em investimento quando economia boa/chamadas longas). Alinha com domínio bancário.")

print("2. Concordância: DT e MI (NB/KNN proxy) concordam em ~70% top features. NB probs destacam econômicas; KNN LIME local varia por instância.")

print("\nFerramentas explicadas:")
print("- Feature Importances (DT): Gini-based, global, intuitiva para árvores (white-box).")
print("- LIME (KNN): Local, approx. linear para black-box; perturba instância para contribuições.")
print("- SHAP (DT): Valores Shapley, fair e aditiva; summary mostra impacto médio.")
print("- Probs Condicionais (NB): Bayes rule, P(class|feat) = P(feat|class)*P(class)/P(feat); simples mas assume indep.")

print("\nLimitações:")
print("- DT: Interpretação fácil, mas overfit se árvore profunda; ignora interações complexas.")
print("- NB: Fácil via probs, mas assume features independentes (fraco em dados correlacionados como job/education).")
print("- KNN: Duro (black-box local); LIME/SHAP ajudam, mas computacional caro para grandes dados; não global.")

# Plot comparativo: Importâncias DT vs. MI.
plt.figure(figsize=(10, 6))
common_feats = list(set(imp_df['feature'].head(10).tolist() + mi_df['feature'].head(10).tolist()))
dt_vals = imp_df[imp_df['feature'].isin(common_feats)]['importance'].values
mi_vals = mi_df[mi_df['feature'].isin(common_feats)]['mutual_info'].values  # Normalize MI for plot.
plt.plot(common_feats, dt_vals, 'o-', label='DT Importância')
plt.plot(common_feats, mi_vals / mi_vals.max() * dt_vals.max(), 's-', label='Mutual Info (NB/KNN proxy)')
plt.xticks(rotation=45)
plt.title("Comparação de Relevância: DT vs. Mutual Info")
plt.legend()
plt.show()

# Conclusões:
print("\nConclusões: Interpretabilidade varia: DT mais direta; NB probabilística; KNN requer approx. (LIME). Importância da interpretabilidade: Em finanças, explica por que 'yes' (ex.: economia), constrói confiança/regulações. Reflexão: Use DT para debug, SHAP para stakeholders.")